#LDA - Linear Discrimination between classes

#D = Predicting a distance between the classes (clusters)

#bigger v = bigger D = clearer separation
#bigger v = better model

#non-parametric = no assumptions
#parametric = assumptions, estimating parameters

#small n = LDA is better than logistic regression, smaller observation

#pie k = probability in being group k
#Fk = Desinity function for X
#sum of function of both above
#LDA = normal distribution assumption

#bayes estimator will not give you a 0% error

#QDA is better when variance are very different and enough observation
#one small spread and the other is a big spread = high variance / low variance

